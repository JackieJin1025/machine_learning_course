{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import scipy.optimize as opt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = \"/Users/Jackie/Dropbox/Work/machine_learning/hw/machine-learning-ex3/ex3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One verse All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(base_dir, 'ex3data1')\n",
    "data = loadmat(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack([np.ones([X.shape[0], 1]), X]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):    \n",
    "    res = 1 / (1+ np.exp(-z))\n",
    "    return res \n",
    "\n",
    "def computeCostReg(theta, X, y, penalty):    \n",
    "    m = len(X)\n",
    "    z = X.dot(theta)\n",
    "    h = sigmoid(z) \n",
    "    \n",
    "    cost = -np.sum((y* np.log(h)  + (1-y) * np.log(1-h) )) / m  \n",
    "    cost = cost + penalty * np.sum(np.power(theta[1:], 2)) / (2*m)\n",
    "            \n",
    "    return cost\n",
    "def gradient(theta, X, y, penalty):\n",
    "    m = len(X)\n",
    "    z = X.dot(theta)\n",
    "    h = sigmoid(z) \n",
    "        \n",
    "    grad0 = (h-y).dot(X[:, 0:1])  / m \n",
    "    grad1 = (h-y).dot(X[:, 1:])  / m + penalty * theta[1:] / m \n",
    "    \n",
    "    grad = np.hstack([grad0, grad1])\n",
    "    \n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "penalty =1\n",
    "m = len(X)\n",
    "n = X.shape[1]\n",
    "theta = np.zeros(n)\n",
    "labels = np.unique(y)\n",
    "num_lables = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, penlaty):\n",
    "    m, n = X.shape\n",
    "    all_theta = np.zeros([num_lables, n])\n",
    "    theta0 = np.zeros(n)    \n",
    "    for i in range(num_lables):            \n",
    "        all_theta[i, :] = opt.fmin_cg(computeCostReg, x0=theta0, fprime=gradient, args=(X, y==i+1, penalty), maxiter=50 )\n",
    "#         fmin = opt.minimize(fun=computeCostReg, x0=theta, args=(X, y==i+1, penalty), method='TNC', jac=gradient)        \n",
    "#         all_theta[i, :] = fmin.x\n",
    "    return all_theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.026968\n",
      "         Iterations: 50\n",
      "         Function evaluations: 169\n",
      "         Gradient evaluations: 169\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.068630\n",
      "         Iterations: 50\n",
      "         Function evaluations: 141\n",
      "         Gradient evaluations: 141\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.071814\n",
      "         Iterations: 50\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 143\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.052088\n",
      "         Iterations: 50\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 154\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.077181\n",
      "         Iterations: 50\n",
      "         Function evaluations: 131\n",
      "         Gradient evaluations: 131\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.034821\n",
      "         Iterations: 50\n",
      "         Function evaluations: 160\n",
      "         Gradient evaluations: 160\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.046841\n",
      "         Iterations: 50\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 151\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.093220\n",
      "         Iterations: 50\n",
      "         Function evaluations: 133\n",
      "         Gradient evaluations: 133\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.089680\n",
      "         Iterations: 50\n",
      "         Function evaluations: 130\n",
      "         Gradient evaluations: 130\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.020151\n",
      "         Iterations: 50\n",
      "         Function evaluations: 170\n",
      "         Gradient evaluations: 170\n",
      "[[-2.41356499e+00  0.00000000e+00  0.00000000e+00 ...  1.23796960e-03\n",
      "   1.33149632e-08  0.00000000e+00]\n",
      " [-3.08597108e+00  0.00000000e+00  0.00000000e+00 ...  3.29695532e-03\n",
      "  -3.77019154e-04  0.00000000e+00]\n",
      " [-4.78056955e+00  0.00000000e+00  0.00000000e+00 ... -2.80474929e-05\n",
      "   9.04283469e-08  0.00000000e+00]\n",
      " ...\n",
      " [-7.97264374e+00  0.00000000e+00  0.00000000e+00 ... -9.14351775e-05\n",
      "   8.08514718e-06  0.00000000e+00]\n",
      " [-4.65851224e+00  0.00000000e+00  0.00000000e+00 ... -5.06660495e-04\n",
      "   3.59419892e-05  0.00000000e+00]\n",
      " [-5.31926037e+00  0.00000000e+00  0.00000000e+00 ... -1.40587613e-04\n",
      "   9.18154740e-06  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#opt.minimize(fun=computeCostReg, x0=theta, args=(X, y==i+1, penalty), method='TNC', jac=gradient)        \n",
    "all_theta = oneVsAll(X, y, num_lables, penalty)\n",
    "print(all_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    z = X.dot(all_theta.transpose())\n",
    "    h = sigmoid(z) \n",
    "    ans = np.argmax(h, axis=1)+1\n",
    "    return ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9434\n"
     ]
    }
   ],
   "source": [
    "#z = X.dot(all_theta.transpose())\n",
    "res = predictOneVsAll(all_theta, X)\n",
    "accuracy = np.sum((res == y))/ len(res)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file2 = os.path.join(base_dir, 'ex3weights')\n",
    "weight_data = loadmat(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26)\n"
     ]
    }
   ],
   "source": [
    "theta1 = weight_data['Theta1']\n",
    "theta2 = weight_data['Theta2']\n",
    "print (theta1.shape, theta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta1, theta2, X): \n",
    "    \"\"\"\n",
    "        feed forward propagation\n",
    "        a column of 1s is already inserted to X\n",
    "    \"\"\"\n",
    "    z2 = X.dot(theta1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    #a2 = np.hstack([np.ones((a2.shape[0], 1)), a2] )\n",
    "    m2 = a2.shape[0]\n",
    "    a2 = np.insert(a2, 0, values=np.ones(m2), axis=1)\n",
    "    \n",
    "    z3 =a2.dot(theta2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    p = np.argmax(a3, axis=1)+1\n",
    "    return p\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9752\n"
     ]
    }
   ],
   "source": [
    "res2 = predict(theta1, theta2, X)\n",
    "accuracy = np.sum((res2 == y))/ len(res2)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
